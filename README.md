# Snowflake Medallion Architecture for Healthcare Data (CCDA, HL7, CSV) with KPIs

This repository implements a **Medallion Architecture (Bronze â†’ Silver â†’ Gold)** on **Snowflake**, ingesting healthcare data from **CCDA**, **HL7**, and **CSV** sources, and generating **KPI dashboards** for clinical insights. It includes **SQL scripts**, **Python utilities**, and **Jupyter notebooks** for reproducible workflows.

---

## âœ… Project Overview
- **Bronze Layer**: Raw ingestion from CCDA, HL7, and CSV files into Snowflake.
- **Silver Layer**: Standardized, cleaned, and normalized data.
- **Gold Layer**: Business-ready tables and KPI calculations.
- **KPIs**: Readmission rates, Post-Discharge Follow-up, Medication Errors.

---

## ğŸ“ Repo Structure
```
snowflake-medallion-project/
â”œâ”€â”€ KPIs/
â”‚   â”œâ”€â”€ GOLD_LAYER_READMISSION_KPI.ipynb
â”‚   â”œâ”€â”€ SILVER_LAYER_READMISSION_KPI.ipynb
â”‚   â”œâ”€â”€ KPI Postâ€‘Discharge Followâ€‘up within 48 hours.txt
â”‚   â”œâ”€â”€ KPI explanation Postâ€‘Discharge Followâ€‘up within 48 hours.txt
â”‚   â”œâ”€â”€ Medication Errors per 100 patients GOLD LAYER TABLES.txt
â”‚   â”œâ”€â”€ Medication Errors per 100 patients Silver layer views.txt
â”‚   â””â”€â”€ text.txt
â”‚
â”œâ”€â”€ SQL/
â”‚   â”œâ”€â”€ final database.sql
â”‚   â”œâ”€â”€ RAW_AND_BRONZE_LAYERS_OF_CSV.sql
â”‚   â”œâ”€â”€ CCDA_FINAL_ASSIGNMENT.sql
â”‚   â”œâ”€â”€ CSV_PARSER.sql
â”‚   â”œâ”€â”€ test.sql
â”‚   â”‚
â”‚   â”œâ”€â”€ CCDA/
â”‚   â”‚   â”œâ”€â”€ ccda.zip
â”‚   â”‚   â”œâ”€â”€ ccdaparser.py
â”‚   â”‚   â””â”€â”€ CCDA_PARSER Master.ipynb
â”‚   â”‚
â”‚   â”œâ”€â”€ CSV/
â”‚   â”‚   â”œâ”€â”€ CSV.txt
â”‚   â”‚   â””â”€â”€ csv_1.zip
â”‚   â”‚
â”‚   â”œâ”€â”€ HL7/
â”‚       â”œâ”€â”€ HL7.txt
â”‚       â”œâ”€â”€ HL7_ADT_1_300.zip
â”‚       â”œâ”€â”€ HL7_ORM_1_100.zip
â”‚       â””â”€â”€ HL7_ORU_1_100.zip
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ CCDA_PARSER Master.ipynb
â”‚   â””â”€â”€ Post Discharge Follow up within 48 hours of the discharge notification.ipynb
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ” Data Sources
- **CCDA**: Clinical documents parsed using `ccdaparser.py` and loaded into Snowflake.
- **HL7**: ADT, ORM, ORU messages processed and staged in Bronze layer.
- **CSV**: Raw CSV files ingested into Snowflake via external stages.

---

## ğŸ§± Medallion Layers
- **Bronze**: Raw ingestion from S3 or local files; minimal schema enforcement.
- **Silver**: Cleaned and standardized tables; deduplication and type enforcement.
- **Gold**: KPI-ready tables for analytics and dashboards.

---

## ğŸ“Š KPIs Implemented
- **Readmission Rate** (Gold Layer)
- **Post-Discharge Follow-up within 48 hours**
- **Medication Errors per 100 patients**

Each KPI has corresponding **notebooks** and **SQL scripts** in the `KPIs/` folder.

---

## ğŸ” Security
- Do **NOT** commit credentials (Snowflake, AWS keys).
- Use `.env` for secrets and add it to `.gitignore`.
- Example `.env`:
```
SNOWFLAKE_ACCOUNT=xxxx
SNOWFLAKE_USER=xxxx
AWS_ACCESS_KEY_ID=xxxx
AWS_SECRET_ACCESS_KEY=xxxx
```

---

## ğŸš€ Setup Instructions
### 1. Clone the repo
```bash
git clone https://github.com/<your-username>/<repo-name>.git
cd <repo-name>
```

### 2. Create virtual environment & install dependencies
```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Configure Snowflake & AWS
- Fill `.env` with Snowflake and AWS credentials.
- Ensure Snowflake roles and warehouses are set up.

---

## ğŸ”— Snowflake & S3 Connections
Example Python connector:
```python
import os
import snowflake.connector
conn = snowflake.connector.connect(
    account=os.getenv("SNOWFLAKE_ACCOUNT"),
    user=os.getenv("SNOWFLAKE_USER"),
    role=os.getenv("SNOWFLAKE_ROLE"),
    warehouse=os.getenv("SNOWFLAKE_WAREHOUSE"),
    database=os.getenv("SNOWFLAKE_DATABASE"),
    schema=os.getenv("SNOWFLAKE_SCHEMA")
)
```

---

## ğŸ“¦ Requirements
```
snowflake-connector-python
boto3
python-dotenv
pandas
jupyter
pytest
```

---

## ğŸ›¡ï¸ Best Practices
- Keep `.env` and zip files out of GitHub.
- Use Snowpipe for automated ingestion.
- Apply masking policies for sensitive data.

---

## ğŸ“š References
- [Snowflake Docs](https://docs.snowflake.com/)
- [AWS S3 Docs](https://docs.aws.amazon.com/s3/)
- [HL7 Standards](https://www.hl7.org/)
